{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "- 모델의 작동 방식을 잘 알고 있으면 적절한 모델, 올바른 훈련 알고리즘, 작업에 맞는 좋은 하이퍼 파라미터를 빠르게 찾을 수 있음\n",
    "- 또한 작동 원리를 이해하면 디버깅이나 에러를 효율적으로 분석하는 데 도움이 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 장의 대부분의 주제는 신경망을 이해하고 구축하고 훈련시키는 데 필수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 가장 간만한 모델 중 하나인 선형 회귀부터 시작. 이 모델을 훈련시키는 두 가지 방법\n",
    " - 직접 계산할 수 있는 공식을 사용하여 훈련 세트에 잘 맞는 모델 파라미터(즉, 훈련 세트에 대해 비용 함수를 최소화하는 모델 파라미터)를 해석학적으로 구하기\n",
    " - 경사하강법(GD)라고 불리는 반복적인 최적화 방식을 사용하여 모델 파라미터를 조금씩 바꾸면서 비용함수를 훈련 세트에 대해 최소화(결국에는 위의 방법과 동일한 파라미터로 수렴)\n",
    "  - 경사 하강법의 변종으로 신경망에서 사용하게 될 배치 경사 하강법, 미니배치 경사 하강법, 확률적 경사 하강법도 살펴 볼 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그 이후에는 비선형 데이터셋에 훈련시킬 수 있는 조금 더 복잡한 모델인 다항 회귀 탐색\n",
    " - 이 모델은 선형 회귀보다 파라미터가 더 많아서 훈련 데이터에 과대적합되기 더 쉬움\n",
    " - 따라서  학습 곡선을 사용해서 모델이 과대적합되는지 감지하는 방법도 탐색할 예정\n",
    "- 그 후, 훈련 세트의 과대적합을 감소시킬 수 있는 규제 기법을 탐색"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 마지막으로 분류 작업에 널리 사용되는 모델인 로지스틱 회귀와 소프트맥스 회귀 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
